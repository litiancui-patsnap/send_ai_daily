#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI æ—¥æŠ¥è‡ªåŠ¨åŒ–ç³»ç»Ÿ
- ä» RSS æºæŠ“å–æœ€è¿‘ 48 å°æ—¶å†…å®¹
- ä½¿ç”¨å¤§æ¨¡å‹ API è¯„åˆ†å¹¶ç”Ÿæˆæ—¥æŠ¥ï¼ˆæ”¯æŒ OpenAI / é€šä¹‰åƒé—®ï¼‰
- å‘é€åˆ°é£ä¹¦ç¾¤ï¼ˆè‡ªå®šä¹‰æœºå™¨äºº + ç­¾åæ ¡éªŒï¼‰
- åŸºäº sha256(link) å»é‡
"""

import os
import sys
import json
import hashlib
import hmac
import base64
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List, Dict

import requests
import feedparser
from dateutil import parser as date_parser


# ==================== é…ç½® ====================
# LLM é…ç½®ï¼ˆæ”¯æŒ OpenAI æˆ–é€šä¹‰åƒé—®ï¼‰
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai").lower()  # openai æˆ– qwen
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY", "")
QWEN_MODEL = os.getenv("QWEN_MODEL", "qwen-plus")

# é£ä¹¦é…ç½®
FEISHU_WEBHOOK_URL = os.getenv("FEISHU_WEBHOOK_URL", "")
FEISHU_SECRET = os.getenv("FEISHU_SECRET", "")

# RSS é…ç½®
RSS_URLS_RAW = os.getenv("RSS_URLS", "")

RSS_URLS = [line.strip() for line in RSS_URLS_RAW.strip().split("\n") if line.strip()]
SENT_HASHES_FILE = Path("data/sent_hashes.txt")
MAX_CANDIDATES = 30
TOP_N = 3
HOURS_WINDOW = 48


# ==================== å·¥å…·å‡½æ•° ====================
def load_sent_hashes() -> set:
    """åŠ è½½å·²å‘é€çš„ hash é›†åˆ"""
    if not SENT_HASHES_FILE.exists():
        SENT_HASHES_FILE.parent.mkdir(parents=True, exist_ok=True)
        SENT_HASHES_FILE.touch()
        return set()
    with open(SENT_HASHES_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f if line.strip())


def save_sent_hashes(hashes: set):
    """ä¿å­˜å·²å‘é€çš„ hash é›†åˆ"""
    SENT_HASHES_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(SENT_HASHES_FILE, "w", encoding="utf-8") as f:
        for h in sorted(hashes):
            f.write(h + "\n")


def hash_link(link: str) -> str:
    """è®¡ç®—é“¾æ¥çš„ sha256 hash"""
    return hashlib.sha256(link.encode("utf-8")).hexdigest()


def is_recent(published_str: str, hours: int = HOURS_WINDOW) -> bool:
    """åˆ¤æ–­æ¡ç›®æ˜¯å¦åœ¨æœ€è¿‘ N å°æ—¶å†…"""
    try:
        pub_time = date_parser.parse(published_str)
        if pub_time.tzinfo is None:
            pub_time = pub_time.replace(tzinfo=timezone.utc)
        now = datetime.now(timezone.utc)
        return (now - pub_time) <= timedelta(hours=hours)
    except Exception:
        return False


# ==================== RSS æŠ“å– ====================
def fetch_rss_entries() -> List[Dict]:
    """ä»æ‰€æœ‰ RSS æºæŠ“å–æœ€è¿‘ 48 å°æ—¶å†…çš„æ¡ç›®"""
    candidates = []
    sent_hashes = load_sent_hashes()

    for url in RSS_URLS:
        try:
            print(f"[INFO] æŠ“å– RSS: {url}")
            feed = feedparser.parse(url)
            for entry in feed.entries:
                link = entry.get("link", "")
                if not link:
                    continue
                link_hash = hash_link(link)
                if link_hash in sent_hashes:
                    continue
                published = entry.get("published", entry.get("updated", ""))
                if not is_recent(published, HOURS_WINDOW):
                    continue
                title = entry.get("title", "")
                summary = entry.get("summary", entry.get("description", ""))
                if len(summary) > 500:
                    summary = summary[:500] + "..."
                candidates.append({
                    "title": title,
                    "link": link,
                    "summary": summary,
                    "published": published,
                    "hash": link_hash
                })
                if len(candidates) >= MAX_CANDIDATES:
                    break
        except Exception as e:
            print(f"[WARN] æŠ“å– {url} å¤±è´¥: {e}")
            continue
        if len(candidates) >= MAX_CANDIDATES:
            break

    print(f"[INFO] å…±æ”¶é›† {len(candidates)} æ¡å€™é€‰")
    return candidates


# ==================== LLM API è°ƒç”¨ ====================
def call_llm_json(system_prompt: str, user_prompt: str) -> Dict:
    """è°ƒç”¨å¤§æ¨¡å‹ APIï¼Œè¦æ±‚è¿”å› JSONï¼ˆæ”¯æŒ OpenAI / é€šä¹‰åƒé—®ï¼‰"""
    if LLM_PROVIDER == "qwen":
        return call_qwen_json(system_prompt, user_prompt)
    else:
        return call_openai_json(system_prompt, user_prompt)


def call_openai_json(system_prompt: str, user_prompt: str, model: str = "gpt-4o-2024-08-06") -> Dict:
    """è°ƒç”¨ OpenAI APIï¼Œè¦æ±‚è¿”å› JSON"""
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "response_format": {"type": "json_object"}
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        resp.raise_for_status()
        data = resp.json()
        content = data["choices"][0]["message"]["content"]
        return json.loads(content)
    except Exception as e:
        print(f"[ERROR] OpenAI API è°ƒç”¨å¤±è´¥: {e}")
        sys.exit(1)


def call_qwen_json(system_prompt: str, user_prompt: str) -> Dict:
    """è°ƒç”¨é€šä¹‰åƒé—® APIï¼Œè¦æ±‚è¿”å› JSON"""
    # æ£€æŸ¥å¿…è¦çš„é…ç½®
    if not DASHSCOPE_API_KEY:
        print("[ERROR] æœªé…ç½® DASHSCOPE_API_KEY")
        sys.exit(1)

    model = QWEN_MODEL if QWEN_MODEL else "qwen-plus"
    print(f"[INFO] ä½¿ç”¨é€šä¹‰åƒé—®æ¨¡å‹: {model}")

    url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
        "Content-Type": "application/json"
    }

    # åˆå¹¶ system å’Œ user prompt
    combined_prompt = f"{system_prompt}\n\n{user_prompt}"

    payload = {
        "model": model,
        "messages": [
            {"role": "user", "content": combined_prompt}
        ],
        "response_format": {"type": "json_object"}
    }

    try:
        print(f"[DEBUG] è¯·æ±‚ URL: {url}")
        print(f"[DEBUG] è¯·æ±‚ model: {payload['model']}")
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        print(f"[DEBUG] å“åº”çŠ¶æ€ç : {resp.status_code}")
        resp.raise_for_status()
        data = resp.json()
        content = data["choices"][0]["message"]["content"]
        return json.loads(content)
    except requests.exceptions.HTTPError as e:
        print(f"[ERROR] é€šä¹‰åƒé—® API HTTP é”™è¯¯: {e}")
        print(f"[DEBUG] å“åº”å†…å®¹: {resp.text}")
        sys.exit(1)
    except Exception as e:
        print(f"[ERROR] é€šä¹‰åƒé—® API è°ƒç”¨å¤±è´¥: {e}")
        print(f"[DEBUG] å“åº”å†…å®¹: {resp.text if 'resp' in locals() else 'No response'}")
        sys.exit(1)


# ==================== è¯„åˆ†é˜¶æ®µ ====================
def score_entries(entries: List[Dict]) -> List[Dict]:
    """ä½¿ç”¨ LLM å¯¹æ¡ç›®æ‰“åˆ†ï¼Œè¿”å› Top N"""
    if not entries:
        return []

    system_prompt = """ä½ æ˜¯ä¸€åèµ„æ·± AI å·¥ç¨‹å¸ˆå’ŒæŠ€æœ¯ç¼–è¾‘ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»ä¸€æ‰¹ RSS æ¡ç›®ä¸­ï¼Œç­›é€‰å‡ºæœ€å€¼å¾—ä¼ä¸šå†…éƒ¨ AI å›¢é˜Ÿå…³æ³¨çš„å†…å®¹ã€‚
è¯„åˆ†æ ‡å‡†ï¼ˆ0~10ï¼‰ï¼š
- å¤§æ¨¡å‹ / AI å¹³å°èƒ½åŠ›æ›´æ–°ï¼š9~10
- Agent / Tool / RAG / ç³»ç»Ÿè®¾è®¡å®è·µï¼š7~9
- äº§å“åº”ç”¨æ¡ˆä¾‹ã€è¯„æµ‹ï¼š5~7
- æ³›æ³›è€Œè°ˆã€è¥é”€è½¯æ–‡ï¼š0~3

è¯·è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼šlink, score, reasonã€‚
åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

    user_prompt = f"""è¯·å¯¹ä»¥ä¸‹ {len(entries)} æ¡ RSS æ¡ç›®æ‰“åˆ†ï¼š

{json.dumps(entries, ensure_ascii=False, indent=2)}

è¿”å›æ ¼å¼ï¼š
{{
  "scores": [
    {{"link": "...", "score": 8.5, "reason": "..."}},
    ...
  ]
}}"""

    result = call_llm_json(system_prompt, user_prompt)
    scores = result.get("scores", [])

    # æŒ‰ score æ’åºï¼Œå– Top N
    scores.sort(key=lambda x: x.get("score", 0), reverse=True)
    top_scores = scores[:TOP_N]

    # è¡¥å……å®Œæ•´æ¡ç›®ä¿¡æ¯
    link_map = {e["link"]: e for e in entries}
    top_entries = []
    for s in top_scores:
        link = s["link"]
        if link in link_map:
            entry = link_map[link].copy()
            entry["score"] = s["score"]
            entry["score_reason"] = s["reason"]
            top_entries.append(entry)

    print(f"[INFO] è¯„åˆ†å®Œæˆï¼ŒTop {TOP_N}: {len(top_entries)} æ¡")
    return top_entries


# ==================== æ—¥æŠ¥ç”Ÿæˆé˜¶æ®µ ====================
def generate_daily_report(top_entries: List[Dict]) -> Dict:
    """ä½¿ç”¨ LLM ç”Ÿæˆæ—¥æŠ¥å†…å®¹"""
    system_prompt = """ä½ æ˜¯ä¼ä¸šå†…éƒ¨"AI æ—¥æŠ¥"æ€»ç¼–è¾‘ã€‚è¯»è€…æ˜¯æ··åˆå›¢é˜Ÿï¼šè€æ¿ã€å¸‚åœºæ€»ç›‘ã€é¡¹ç›®ç»ç†ã€å”®å‰ã€ç®—æ³•ã€å‰ç«¯ã€åç«¯ã€UIã€æµ‹è¯•ã€æµ‹ç»˜ã€‚
ä½ å¿…é¡»è¾“å‡ºä¸¥æ ¼ JSONï¼ˆä¸è¦ markdownã€ä¸è¦è§£é‡Šã€ä¸è¦å¤šä½™æ–‡æœ¬ï¼‰ã€‚
å†™ä½œé£æ ¼ï¼šå°‘åºŸè¯ã€å¼ºç»“è®ºã€å¯è¡ŒåŠ¨ï¼›ç¦æ­¢è¥é”€è¯­ã€ç¦æ­¢æ„Ÿå¹å·ã€ç¦æ­¢"å¯å…³æ³¨/æœ‰ä¸€å®šå¸®åŠ©"ç­‰ç©ºè¯ã€‚
é•¿åº¦ç›®æ ‡ï¼šæ•´ä½“å†…å®¹çº¦ 200~280 ä¸ªä¸­æ–‡å­—ç¬¦ï¼ˆä¸å« URLï¼‰ã€‚"""

    today = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d")

    user_prompt = f"""åŸºäºä»¥ä¸‹ Top 3 RSS æ¡ç›®ï¼Œç”Ÿæˆä¸€å¼ "ç»ˆç‰ˆ AI æ—¥æŠ¥å¡ç‰‡"çš„ JSONï¼ˆä¸­æ–‡ï¼‰ï¼Œç»“æ„å¿…é¡»å®Œå…¨ç¬¦åˆä¸‹é¢çš„ JSON å¥‘çº¦ã€‚

ã€Top 3 æ¡ç›®ã€‘
{json.dumps(top_entries, ensure_ascii=False, indent=2)}

ã€JSON å¥‘çº¦ã€‘
{{
  "date": "{today}",
  "theme": "ä»Šæ—¥ä¸»é¢˜ä¸€å¥è¯ï¼ˆå‘ç”Ÿäº†ä»€ä¹ˆ + ä¸ºä»€ä¹ˆé‡è¦ï¼‰",
  "decision": {{
    "level": "å€¼å¾—å…³æ³¨|éœ€è¦è¯•ç‚¹|æš‚ä¸è¡ŒåŠ¨",
    "reason": "â‰¤15å­—åŸå› "
  }},
  "core_changes": ["1æ¡ä¸ºä½³ï¼Œæœ€å¤š2æ¡ï¼ˆä¸»è§’å˜åŒ–ï¼ŒéèƒŒæ™¯ï¼‰"],
  "related": ["0-2æ¡å¯é€‰ï¼ˆè¡¥å……ä¿¡æ¯ï¼‰"],
  "impacts": {{
    "business": {{
      "boss": "ä¸€å¥è¯åˆ¤æ–­ä»·å€¼/é£é™©",
      "market": "ä¸€å¥è¯å½±å“å¯¹å¤–å™äº‹/æ–¹æ¡ˆ",
      "pm": "ä¸€å¥è¯å½±å“äº¤ä»˜/è¯„ä¼°"
    }},
    "tech": {{
      "algo": "ä¸€å¥è¯å½±å“æ¨¡å‹/Agentè®¾è®¡",
      "frontend": "ä¸€å¥è¯å½±å“äº¤äº’/å±•ç¤º",
      "backend": "ä¸€å¥è¯å½±å“æ¶æ„/æ—¥å¿—/æˆæœ¬",
      "qa": "ä¸€å¥è¯å½±å“æµ‹è¯•/å®šä½"
    }},
    "delivery": {{
      "ui": "ä¸€å¥è¯å½±å“è®¾è®¡ä¾æ®/åé¦ˆ",
      "presales": "ä¸€å¥è¯å½±å“æ–¹æ¡ˆå¯ä¿¡åº¦/è¯´æœåŠ›",
      "surveying": "ä¸€å¥è¯å½±å“æ ‡æ³¨/è´¨æ£€/äº¤ä»˜é€æ˜åº¦"
    }}
  }},
  "action": {{
    "label": "ğŸ§ªå»ºè®®è¯•ç‚¹|ğŸ‘€æŒç»­è§‚å¯Ÿ|âŒå¯å¿½ç•¥",
    "detail": "å»ºè®®ï¼šç”±è°åœ¨ä»€ä¹ˆåœºæ™¯éªŒè¯ä»€ä¹ˆ"
  }},
  "sources": [{{"title": "...", "link": "..."}}]
}}

ã€ç¡¬çº¦æŸã€‘
- impacts æ¯ä¸ªå­—æ®µéƒ½å¿…é¡»æœ‰å†…å®¹ï¼›å¦‚æœæš‚æ— æ˜æ˜¾å½±å“ï¼Œå†™"æš‚æ— æ˜æ˜¾å½±å“"
- core_changes ä¸è¦è¶…è¿‡2æ¡ï¼›related å…è®¸ä¸ºç©ºæ•°ç»„
- sources å¿…é¡»æ¥è‡ª Top 3 æ¡ç›®çš„ title/linkï¼Œæœ€å¤š3æ¡
- ä¸å…è®¸å‡ºç°"å¯å…³æ³¨/æœ‰ä¸€å®šå¸®åŠ©/å€¼å¾—ä¸€æ"ç­‰ç©ºå¥
- theme è¦ä½“ç°"å˜åŒ–æœ¬èº« + ä¸šåŠ¡ä»·å€¼"ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ"""

    report = call_llm_json(system_prompt, user_prompt)
    return validate_and_fix_report(report)


def validate_and_fix_report(report: Dict) -> Dict:
    """æ ¡éªŒå¹¶ä¿®å¤æ—¥æŠ¥ JSON ç»“æ„ï¼Œç¡®ä¿å­—æ®µå®Œæ•´"""
    # é»˜è®¤å€¼
    default_report = {
        "date": datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d"),
        "theme": "AI æŠ€æœ¯åŠ¨æ€",
        "decision": {"level": "æŒç»­è§‚å¯Ÿ", "reason": "å¾…è¿›ä¸€æ­¥è¯„ä¼°"},
        "core_changes": [],
        "related": [],
        "impacts": {
            "business": {
                "boss": "æš‚æ— æ˜æ˜¾å½±å“",
                "market": "æš‚æ— æ˜æ˜¾å½±å“",
                "pm": "æš‚æ— æ˜æ˜¾å½±å“"
            },
            "tech": {
                "algo": "æš‚æ— æ˜æ˜¾å½±å“",
                "frontend": "æš‚æ— æ˜æ˜¾å½±å“",
                "backend": "æš‚æ— æ˜æ˜¾å½±å“",
                "qa": "æš‚æ— æ˜æ˜¾å½±å“"
            },
            "delivery": {
                "ui": "æš‚æ— æ˜æ˜¾å½±å“",
                "presales": "æš‚æ— æ˜æ˜¾å½±å“",
                "surveying": "æš‚æ— æ˜æ˜¾å½±å“"
            }
        },
        "action": {"label": "ğŸ‘€æŒç»­è§‚å¯Ÿ", "detail": "å»ºè®®ï¼šæŒç»­å…³æ³¨ç›¸å…³åŠ¨æ€"},
        "sources": []
    }

    # åˆå¹¶é»˜è®¤å€¼
    for key, default_value in default_report.items():
        if key not in report:
            report[key] = default_value
            print(f"[WARN] ç¼ºå¤±å­—æ®µ {key}ï¼Œä½¿ç”¨é»˜è®¤å€¼")

    # æ ¡éªŒå¹¶ä¿®å¤ impacts
    if "impacts" in report:
        for group in ["business", "tech", "delivery"]:
            if group not in report["impacts"]:
                report["impacts"][group] = default_report["impacts"][group]
            else:
                for role, default_text in default_report["impacts"][group].items():
                    if role not in report["impacts"][group] or not report["impacts"][group][role]:
                        report["impacts"][group][role] = default_text

    # æ ¡éªŒå¹¶ä¿®å¤ decision
    if "decision" not in report or not isinstance(report["decision"], dict):
        report["decision"] = default_report["decision"]
    else:
        if "level" not in report["decision"]:
            report["decision"]["level"] = "æŒç»­è§‚å¯Ÿ"
        if "reason" not in report["decision"]:
            report["decision"]["reason"] = "å¾…è¿›ä¸€æ­¥è¯„ä¼°"

    # æˆªæ–­ core_changesï¼ˆæœ€å¤š2æ¡ï¼‰
    if "core_changes" in report and isinstance(report["core_changes"], list):
        report["core_changes"] = report["core_changes"][:2]

    # æˆªæ–­ relatedï¼ˆæœ€å¤š2æ¡ï¼‰
    if "related" in report and isinstance(report["related"], list):
        report["related"] = report["related"][:2]
    else:
        report["related"] = []

    # æˆªæ–­ sourcesï¼ˆæœ€å¤š3æ¡ï¼‰
    if "sources" in report and isinstance(report["sources"], list):
        report["sources"] = report["sources"][:3]

    # æ ¡éªŒ action
    if "action" not in report or not isinstance(report["action"], dict):
        report["action"] = default_report["action"]
    else:
        if "label" not in report["action"]:
            report["action"]["label"] = "ğŸ‘€æŒç»­è§‚å¯Ÿ"
        if "detail" not in report["action"]:
            report["action"]["detail"] = "å»ºè®®ï¼šæŒç»­å…³æ³¨ç›¸å…³åŠ¨æ€"

    print(f"[INFO] æ—¥æŠ¥ç»“æ„æ ¡éªŒå®Œæˆ")
    return report


# ==================== é£ä¹¦æ¨é€ ====================
def send_to_feishu(report: Dict):
    """å‘é€æ—¥æŠ¥åˆ°é£ä¹¦ç¾¤ï¼ˆå¸¦ç­¾åæ ¡éªŒï¼‰"""
    if not FEISHU_WEBHOOK_URL:
        print("[WARN] æœªé…ç½® FEISHU_WEBHOOK_URLï¼Œè·³è¿‡å‘é€")
        return

    # ç­¾å
    timestamp = str(int(time.time()))
    sign = ""
    if FEISHU_SECRET:
        string_to_sign = f"{timestamp}\n{FEISHU_SECRET}"
        hmac_code = hmac.new(
            string_to_sign.encode("utf-8"),
            digestmod=hashlib.sha256
        ).digest()
        sign = base64.b64encode(hmac_code).decode("utf-8")

    # æ„å»º impacts åˆ†ç»„åˆ—è¡¨ï¼ˆæŒ‰ç»ˆç‰ˆæ¨¡æ¿ï¼šä¸šåŠ¡/æŠ€æœ¯/äº¤ä»˜ï¼‰
    impacts = report.get("impacts", {})

    # ğŸ¯ ä¸šåŠ¡ / å†³ç­–å±‚
    business_impacts = impacts.get("business", {})
    business_text = f"**è€æ¿**: {business_impacts.get('boss', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    business_text += f"**å¸‚åœº**: {business_impacts.get('market', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    business_text += f"**äº§å“ç»ç†**: {business_impacts.get('pm', 'æš‚æ— æ˜æ˜¾å½±å“')}"

    # ğŸ§  æŠ€æœ¯å®ç°å±‚
    tech_impacts = impacts.get("tech", {})
    tech_text = f"**ç®—æ³•å·¥ç¨‹å¸ˆ**: {tech_impacts.get('algo', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    tech_text += f"**å‰ç«¯å·¥ç¨‹å¸ˆ**: {tech_impacts.get('frontend', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    tech_text += f"**åç«¯å·¥ç¨‹å¸ˆ**: {tech_impacts.get('backend', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    tech_text += f"**æµ‹è¯•å·¥ç¨‹å¸ˆ**: {tech_impacts.get('qa', 'æš‚æ— æ˜æ˜¾å½±å“')}"

    # ğŸ¨ ä½“éªŒä¸äº¤ä»˜å±‚
    delivery_impacts = impacts.get("delivery", {})
    delivery_text = f"**UIè®¾è®¡å¸ˆ**: {delivery_impacts.get('ui', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    delivery_text += f"**å”®å‰**: {delivery_impacts.get('presales', 'æš‚æ— æ˜æ˜¾å½±å“')}\n"
    delivery_text += f"**é¡¹ç›®ç»ç†**: {delivery_impacts.get('surveying', 'æš‚æ— æ˜æ˜¾å½±å“')}"

    # æ„å»º core_changes åˆ—è¡¨
    core_changes = report.get("core_changes", [])
    changes_text = "\n".join([f"â€¢ {c}" for c in core_changes]) if core_changes else "æš‚æ— "

    # æ„å»º related åˆ—è¡¨
    related = report.get("related", [])
    related_text = "\n".join([f"â€¢ {r}" for r in related]) if related else ""

    # æ„å»º sources åˆ—è¡¨
    sources = report.get("sources", [])
    sources_text = ""
    for idx, src in enumerate(sources, 1):
        sources_text += f"{idx}. [{src.get('title', 'æœªçŸ¥æ¥æº')}]({src.get('link', '#')})\n"
    if not sources_text:
        sources_text = "æš‚æ— æ¥æº"

    # è·å–å†³ç­–æç¤º
    decision = report.get("decision", {})
    decision_level = decision.get("level", "æŒç»­è§‚å¯Ÿ")
    decision_reason = decision.get("reason", "å¾…è¿›ä¸€æ­¥è¯„ä¼°")

    # è·å–è¡ŒåŠ¨å»ºè®®
    action = report.get("action", {})
    action_label = action.get("label", "ğŸ‘€æŒç»­è§‚å¯Ÿ")
    action_detail = action.get("detail", "å»ºè®®ï¼šæŒç»­å…³æ³¨ç›¸å…³åŠ¨æ€")

    # æ„å»ºå¡ç‰‡å…ƒç´ åˆ—è¡¨
    elements = [
        # ä»Šæ—¥ä¸»é¢˜
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**ğŸ“Œ ä»Šæ—¥ä¸»é¢˜**\n{report.get('theme', 'AI æŠ€æœ¯åŠ¨æ€')}"}
        },
        {"tag": "hr"},
        # å†³ç­–æç¤º
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**âš¡ å†³ç­–æç¤º**: {decision_level}\nğŸ’¡ {decision_reason}"}
        },
        {"tag": "hr"},
        # æ ¸å¿ƒæŠ€æœ¯å˜åŒ–
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**ğŸ”§ æ ¸å¿ƒæŠ€æœ¯å˜åŒ–**\n{changes_text}"}
        }
    ]

    # ç›¸å…³è¡¥å……ï¼ˆå¯é€‰ï¼‰
    if related_text:
        elements.append({"tag": "hr"})
        elements.append({
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**ğŸ“ ç›¸å…³è¡¥å……**\n{related_text}"}
        })

    # è§’è‰²å½±å“é€Ÿè§ˆï¼ˆåˆ†ç»„ï¼‰
    elements.extend([
        {"tag": "hr"},
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**ğŸ‘¥ è§’è‰²å½±å“é€Ÿè§ˆ**\n\nğŸ¯ **ä¸šåŠ¡ / å†³ç­–å±‚**\n{business_text}"}
        },
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"ğŸ§  **æŠ€æœ¯å®ç°å±‚**\n{tech_text}"}
        },
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"ğŸ¨ **ä½“éªŒä¸äº¤ä»˜å±‚**\n{delivery_text}"}
        },
        {"tag": "hr"},
        # è¡ŒåŠ¨å»ºè®®
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**ğŸš€ è¡ŒåŠ¨å»ºè®®**: {action_label}\n{action_detail}"}
        },
        {"tag": "hr"},
        # æ¥æº
        {
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**ğŸ“š æ¥æº**\n{sources_text}"}
        }
    ])

    card_content = {
        "config": {"wide_screen_mode": True},
        "header": {
            "title": {"tag": "plain_text", "content": f"ğŸ“° AI æ—¥æŠ¥ | {report.get('date', datetime.now().strftime('%Y-%m-%d'))}"},
            "template": "blue"
        },
        "elements": elements
    }

    payload = {
        "timestamp": timestamp,
        "sign": sign,
        "msg_type": "interactive",
        "card": card_content
    }

    # é‡è¯•æœºåˆ¶
    for attempt in range(3):
        try:
            resp = requests.post(FEISHU_WEBHOOK_URL, json=payload, timeout=10)
            resp.raise_for_status()
            result = resp.json()
            if result.get("code") == 0:
                print("[INFO] é£ä¹¦æ¨é€æˆåŠŸ")
                return
            else:
                print(f"[WARN] é£ä¹¦æ¨é€å¤±è´¥: {result}")
        except Exception as e:
            print(f"[WARN] é£ä¹¦æ¨é€å¼‚å¸¸ (attempt {attempt+1}): {e}")
            if attempt < 2:
                time.sleep(2 ** attempt)
    print("[ERROR] é£ä¹¦æ¨é€æœ€ç»ˆå¤±è´¥")


# ==================== ä¸»æµç¨‹ ====================
def main():
    print(f"[INFO] å¼€å§‹æ‰§è¡Œ AI æ—¥æŠ¥ä»»åŠ¡ - {datetime.now().isoformat()}")

    # 1. æŠ“å– RSS
    candidates = fetch_rss_entries()
    if not candidates:
        print("[INFO] æ— æ–°å†…å®¹ï¼Œé€€å‡º")
        return

    # 2. è¯„åˆ†
    top_entries = score_entries(candidates)
    if not top_entries:
        print("[INFO] æ— é«˜åˆ†å†…å®¹ï¼Œé€€å‡º")
        return

    # 3. ç”Ÿæˆæ—¥æŠ¥
    report = generate_daily_report(top_entries)
    print("[INFO] æ—¥æŠ¥ç”Ÿæˆå®Œæˆ")
    print(json.dumps(report, ensure_ascii=False, indent=2))

    # 4. å‘é€é£ä¹¦
    send_to_feishu(report)

    # 5. æ›´æ–°å»é‡æ–‡ä»¶
    sent_hashes = load_sent_hashes()
    new_hashes = {e["hash"] for e in top_entries}
    sent_hashes.update(new_hashes)
    save_sent_hashes(sent_hashes)
    print(f"[INFO] å·²æ›´æ–°å»é‡æ–‡ä»¶ï¼Œæ–°å¢ {len(new_hashes)} æ¡")


if __name__ == "__main__":
    main()
